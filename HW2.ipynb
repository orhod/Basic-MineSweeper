{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orhod/Basic-MineSweeper/blob/main/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Package installations"
      ],
      "metadata": {
        "id": "dcnWzreI_3vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip installs\n",
        "!pip install firebase\n",
        "!pip install gradio\n",
        "!pip install paho-mqtt\n",
        "\n",
        "#================================= make sure all pip installs are above this line ============================================\n",
        "\n",
        "# import to clear the installation code output\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "jVQsBoLZs6zd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import gradio as gr\n",
        "import json\n",
        "import time\n",
        "from firebase import firebase\n",
        "import paho.mqtt.client as mqtt\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from typing_extensions import Never\n",
        "import os\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "stAxnFFt27_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36ca47b-b8ce-4c2f-d3bb-0a1f486384fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DBLink = \"https://wordbank-c75f1-default-rtdb.firebaseio.com/\"\n"
      ],
      "metadata": {
        "id": "jg6v4N0MSpnc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Admin panel functions"
      ],
      "metadata": {
        "id": "NX3opH8Nr0qq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qo04PSwNr5qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index"
      ],
      "metadata": {
        "id": "IHJCMr7qrwDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DbService:\n",
        "    def __init__(self,Dblink):\n",
        "        self.dbLink= Dblink\n",
        "\n",
        "    def insert_to_db(self,results):\n",
        "        FBconn = firebase.FirebaseApplication(self.dbLink,None)\n",
        "        FBconn.put('/','terms',results)\n",
        "\n",
        "    def get_from_db(self):\n",
        "        FBconn = firebase.FirebaseApplication(self.dbLink,None)\n",
        "        results = FBconn.get('/','terms')\n",
        "        return results\n",
        "\n",
        "\n",
        "class QueryService:\n",
        "    def __init__(self,url):\n",
        "        self.url = url\n",
        "\n",
        "    def fetch_page(self):\n",
        "        response = requests.get(self.url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            return soup\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def index_words(self, soup, index = {}, url = ''):\n",
        "        words = re.findall(r'\\w+', soup.get_text())\n",
        "        for word in words:\n",
        "            word = word.lower()\n",
        "            if word in index:\n",
        "                index[word][\"Appearences\"] += 1\n",
        "                # Add URL to docid if it's not already there\n",
        "                if url and url not in index[word][\"DocIDs\"]:\n",
        "                    index[word][\"DocIDs\"].append(url)\n",
        "            else:\n",
        "                # Initialize with count and docid list containing the current URL\n",
        "                index[word] = {\"Appearences\": 1, \"DocIDs\": [url] if url else []}\n",
        "\n",
        "        return index\n",
        "\n",
        "    def remove_stop_words(self,index):\n",
        "      stop_words = set(stopwords.words('english'))\n",
        "      for stop_word in stop_words:\n",
        "        if stop_word in index:\n",
        "          del index[stop_word]\n",
        "      return index\n",
        "\n",
        "class Crawler:\n",
        "  def __init__(self, url):\n",
        "    self.url = url\n",
        "\n",
        "  #Fetches all sub urls from a given url\n",
        "  def get_sub_urls(self, url):\n",
        "    sub_urls = []\n",
        "    stack = [url]\n",
        "    while stack:\n",
        "      url = stack.pop()\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()  # Raise an exception for bad responses\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "      for link in soup.find_all('a', href=True):\n",
        "          href = link['href']\n",
        "          absolute_url = urljoin(url, href)  # Make URL absolute\n",
        "\n",
        "          if (absolute_url.startswith(url)) and (absolute_url != url) and (absolute_url not in sub_urls):\n",
        "              sub_urls.append(absolute_url)\n",
        "              stack.append(absolute_url)\n",
        "\n",
        "    return sub_urls\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  dbService = DbService(DBLink)\n",
        "  url = \"https://mqtt.org/\"\n",
        "  crawler = Crawler(url)\n",
        "  sub_urls = crawler.get_sub_urls(url)\n",
        "  index = {}\n",
        "  for sub_url in sub_urls:\n",
        "    queryService = QueryService(sub_url)\n",
        "    soup = queryService.fetch_page()\n",
        "    index = queryService.index_words(soup, index, sub_url)\n",
        "    index = queryService.remove_stop_words(index)\n",
        "  dbService.insert_to_db(index)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "tu4wr_EOr5Si"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Search Engine UI"
      ],
      "metadata": {
        "id": "14KezAjR8jiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def search_word(query):\n",
        "    if not query:\n",
        "        return \"Please enter a search term\"\n",
        "\n",
        "    # Get the index from the database\n",
        "    dbService = DbService(DBLink)\n",
        "    index = dbService.get_from_db()\n",
        "\n",
        "    if not index:\n",
        "        return \"No index found in the database. Please run the indexing process first.\"\n",
        "\n",
        "    # Process the query - split into individual words\n",
        "    words = re.findall(r'\\w+', query.lower())\n",
        "\n",
        "    if not words:\n",
        "        return \"Please enter valid search terms\"\n",
        "\n",
        "    # Dictionary to track all found URLs and their related words\n",
        "    all_results = {}\n",
        "    # Dictionary to track word appearance counts\n",
        "    word_appearances = {}\n",
        "    # Keep track of words not found\n",
        "    words_not_found = []\n",
        "\n",
        "    # Search for each word in the index\n",
        "    for word in words:\n",
        "        if word in index:\n",
        "            urls = index[word][\"DocIDs\"]\n",
        "            appearances = index[word][\"Appearences\"]\n",
        "            word_appearances[word] = appearances\n",
        "\n",
        "            # Add each URL to the results dictionary\n",
        "            for url in urls:\n",
        "                if url in all_results:\n",
        "                    all_results[url].append(word)\n",
        "                else:\n",
        "                    all_results[url] = [word]\n",
        "        else:\n",
        "            words_not_found.append(word)\n",
        "\n",
        "    # Format the results\n",
        "    if not all_results:\n",
        "        return f\"No results found for any of the search terms: {', '.join(words)}\"\n",
        "\n",
        "    # Count the total number of URLs found and appearances\n",
        "    total_urls = len(all_results)\n",
        "    total_appearances = sum(word_appearances.values())\n",
        "\n",
        "    # Start building the result string\n",
        "    result = f\"Found {len(words) - len(words_not_found)} of {len(words)} search terms in {total_urls} pages with {total_appearances} total appearances:\\n\\n\"\n",
        "\n",
        "    # Sort results by number of matching words (most matches first)\n",
        "    sorted_results = sorted(all_results.items(), key=lambda x: len(x[1]), reverse=True)\n",
        "\n",
        "    for i, (url, found_words) in enumerate(sorted_results, 1):\n",
        "        result += f\"{i}. {url} \\n Contains words: \\t {', '.join(found_words)}\\n\\n\"\n",
        "\n",
        "    # Add information about words not found\n",
        "    if words_not_found:\n",
        "        result += f\"\\nTerms not found: {', '.join(words_not_found)}\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Create the Gradio interface for the search engine\n",
        "search_interface = gr.Interface(\n",
        "    fn=search_word,\n",
        "    inputs=gr.Textbox(placeholder=\"Enter words to search...\"),\n",
        "    outputs=gr.Textbox(label=\"Search Results\", lines=10),\n",
        "    title=\"Multi-Word Search Engine\",\n",
        "    description=\"Search for multiple words and find the URLs where they appear.\",\n",
        "    allow_flagging='never',\n",
        ")\n",
        "\n",
        "# Launch the search interface\n",
        "search_interface.launch(inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "9TfPf3my4mXr",
        "outputId": "3e13d82b-eab1-41e0-d3c6-d5dcea7d6f7a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://40e20892b8c42cc205.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://40e20892b8c42cc205.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sensor data caching and processing"
      ],
      "metadata": {
        "id": "Hcrgrrw_qF5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUN71RiATiOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42866be8-3700-414e-9a51-afbee1e7b97f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-6ed2c8020976>:57: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
            "  client = mqtt.Client()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to MQTT Broker!\n",
            "Subscribing to topics\n",
            "Successfully subscribed to topics!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MQTTErrorCode.MQTT_ERR_SUCCESS: 0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Data proccessing\n",
        "#def process_data(data):\n",
        "\n",
        "db_url = \"https://project-pheonix-39eef-default-rtdb.europe-west1.firebasedatabase.app/\"\n",
        "FBconn = firebase.FirebaseApplication(db_url,None)\n",
        "\n",
        "# Data saving in DB\n",
        "def send_to_db(path, data):\n",
        "  FBconn.put('/',f'/fake/{path}',data)\n",
        "  return\n",
        "\n",
        "# create an mqtt connection\n",
        "def on_connect(client, userdata, flags, rc):\n",
        "  if rc == 0:\n",
        "    print(\"Connected to MQTT Broker!\\nSubscribing to topics\")\n",
        "\n",
        "    # Subscribe to the relevant topics\n",
        "    client.subscribe(\"braude/D106/indoor\")\n",
        "    client.subscribe(\"braude/D106/outdoor\")\n",
        "\n",
        "    print(\"Successfully subscribed to topics!\")\n",
        "  else:\n",
        "    print(f\"Failed to connect, return code {rc}\")\n",
        "\n",
        "def on_disconnect(client, userdata, rc):\n",
        "  if rc != 0:\n",
        "    for i in range(5):\n",
        "      print(f\"Unexpected disconnection (error code: {rc}). Attempting to reconnect number {i + 1} in 5 seconds...\")\n",
        "      time.sleep(5)\n",
        "      try:\n",
        "        client.reconnect()\n",
        "      except Exception as e:\n",
        "        print(f\"Reconnection attempt failed: {e}\")\n",
        "\n",
        "def on_message(client, userdata, msg):\n",
        "\n",
        "  topic = msg.topic\n",
        "  payload = msg.payload.decode('utf-8')  # Decode the byte string to a string\n",
        "\n",
        "  print(f\"Received JSON message on topic '{topic}': {payload}\")\n",
        "  entry = None\n",
        "  try:\n",
        "    sensor_data = json.loads(payload)\n",
        "    print(f\"Parsed JSON data: {sensor_data}\")\n",
        "\n",
        "    if topic == \"braude/D106/indoor\":\n",
        "      send_to_db(f\"indoor/{int(time.time())}\", sensor_data)\n",
        "\n",
        "    elif topic == \"braude/D106/outdoor\":\n",
        "      send_to_db(f\"outdoor/{int(time.time())}\", sensor_data)\n",
        "\n",
        "  except json.JSONDecodeError as e:\n",
        "    print(f\"Error decoding JSON: {e}\")\n",
        "    print(f\"Problematic payload: {payload}\")\n",
        "\n",
        "# connect to the MQTT publisher\n",
        "client = mqtt.Client()\n",
        "client.on_connect = on_connect\n",
        "client.on_disconnect = on_disconnect\n",
        "client.on_message = on_message\n",
        "client.connect(\"broker.hivemq.com\", 1883, keepalive = 600)\n",
        "client.loop_start()\n",
        "\n",
        "time.sleep(5)\n",
        "client.loop_stop()\n",
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Screens"
      ],
      "metadata": {
        "id": "YwHW4vX0rsJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "# Sensor data pulling from DB\n",
        "data = FBconn.get('/fake/indoor',None)\n",
        "data_keys = list(data.keys())\n",
        "data_values = list(data.values())\n",
        "readable_times = [datetime.utcfromtimestamp(int(ts)).strftime('%H:%M:%S') for ts in data_keys]\n",
        "\n",
        "#values for each indoor sensor\n",
        "data_values_Distance = [value['Distance'] for value in data_values]\n",
        "data_values_Temperature = [value['Temperature'] for value in data_values]\n",
        "data_values_Humidity = [value['Humidity'] for value in data_values]\n",
        "data_values_Pressure = [value['Pressure'] for value in data_values]\n",
        "\n",
        "# Data visualization\n",
        "def plot_graph(name):\n",
        "    val_arr = [value[name] for value in data_values]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=readable_times, y=val_arr, mode='lines+markers', name=name))\n",
        "    fig.update_layout(title='Sensor {} Over Time'.format(name), xaxis_title='Time', yaxis_title=name)\n",
        "    return fig\n",
        "\n",
        "# Gradio interface\n",
        "gr.Interface(fn=plot_graph, inputs=gr.Dropdown(['Distance','Temperature','Humidity','Pressure']), outputs=gr.Plot(label=\"Graph\")).launch(inline=True)\n"
      ],
      "metadata": {
        "id": "FWaIWGy0rCBG",
        "outputId": "9108a44d-4625-4d14-d911-f5490cc19d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d8a5920b371ce9e002.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d8a5920b371ce9e002.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}